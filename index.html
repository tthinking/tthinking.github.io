
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Wei Tang's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Wei Tang is currently a Ph.D. student at Wuhan University">
  <meta name="keywords" content="Wei Tang, 唐伟,weitang, Wei, Tang, Deep Learning, Image  Processing, Information Fusion, Computer, Vision">
  <meta name="author" content="Wei Tang" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="weitang" type="image/jpg" href="./images/weitang.jpg">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>WEI</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#Home" class="w3-bar-item w3-button">Home</a>
    <a href="#News" class="w3-bar-item w3-button">News</a>
    <a href="#Publications" class="w3-bar-item w3-button"Publications</a>
    <a href="#Services" class="w3-bar-item w3-button">Services</a>
    <a href="#Selected Honors & Awards" class="w3-bar-item w3-button"Selected Honors & Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">WEI TANG</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 320px" alt="profile photo" src="images/weitang.jpg">
      <h1>Wei Tang</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          I am a Ph.D. stduent at <a href="http://cs.whu.edu.cn/">School of Computer Science, Wuhan University</a>.
        </p>
        <p class="w3-center">
          <a href="weitang2021@whu.edu.cn">weitang2021@whu.edu.cn</a> &nbsp/&nbsp
          <a href="https://scholar.google.com.hk/citations?user=fyNWjaAAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
          <a href="https://www.researchgate.net/profile/Wei-Tang-92"> Research Gate </a> &nbsp/&nbsp
          <a href="https://github.com/tthinking"> GitHub </a>
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <p><li> 07/2022, 1 paper has been accepted by TIP. <a href="https://ieeexplore.ieee.org/document/9844446">Paper</a> <a href="https://github.com/tthinking/MATR">Code</a></li></p>
      <p><li> 07/2022, 1 paper has been accepted by TMM. <a href="https://ieeexplore.ieee.org/document/9834137">Paper</a> <a href="https://github.com/tthinking/YDTR">Code</a></li></p>
   	 

  </div>

 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publications">
    <h2>Research</h2>
      <p class="w3-left-align" style="line-height:200%">
        I'm interested in devleoping <strong>efficient models</strong> for computer vision (e.g. classification, detection, and super-resolution) using pruning, quantization, distilaltion, NAS, etc.
      </p>
    <h4> Conference Papers:</h4>

    <ol>

      <p>
      <li><strong>Spatial-Channel Token Distillation for Vision MLPs</strong>
      <br>
      Yanxi Li, Xinghao Chen, Minjing Dong, Yehui Tang, <strong>Yunhe Wang</strong>, Chang Xu
      <br>
      <em>ICML</em> 2022 | <a style="color: #447ec9" href="https://proceedings.mlr.press/v162/li22c/li22c.pdf">paper</a> 
      </p>

      <p>
      <li><strong>Federated Learning with Positive and Unlabeled Data</strong>
      <br>
      Xinyang Lin*, Hanting Chen*, Yixing Xu, Chao Xu, Xiaolin Gui, Yiping Deng, <strong>Yunhe Wang</strong>
      <br>
      <em>ICML</em> 2022 (* equal contribution) | <a style="color: #447ec9" href="https://proceedings.mlr.press/v162/lin22b/lin22b.pdf">paper</a>
      </p>

      <p>
      <li><strong>CMT: Convolutional Neural Networks Meet Vision Transformers</strong>
      <br>
      Jianyuan Guo, Kai Han, Han Wu, Yehui Tang, Xinghao Chen, <strong>Yunhe Wang</strong>, Chang Xu 
      <br>
      <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_CMT_Convolutional_Neural_Networks_Meet_Vision_Transformers_CVPR_2022_paper.pdf">paper</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/CMT">MindSpore code</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/Efficient-AI-Backbones">Pytorch code</a>
      </p>

      <p>
      <li><strong>Patch Slimming for Efficient Vision Transformers</strong>
      <br>
      Yehui Tang, Kai Han, <strong>Yunhe Wang</strong>, Chang Xu, Jianyuan Guo, Chao Xu, Dacheng Tao
      <br>
      <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_Patch_Slimming_for_Efficient_Vision_Transformers_CVPR_2022_paper.pdf">paper</a>
      </p>

      <p>
      <li><strong>An Image Patch Is a Wave: Phase-Aware Vision MLP</strong>
      <br>
      Yehui Tang, Kai Han, Jianyuan Guo, Chang Xu, Yanxi Li, Chao Xu, <strong>Yunhe Wang</strong>
      <br>
      <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Tang_An_Image_Patch_Is_a_Wave_Phase-Aware_Vision_MLP_CVPR_2022_paper.pdf">paper</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/wave_mlp">MindSpore code</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/CV-Backbones/tree/master/wavemlp_pytorch">Pytorch code</a>
      </p>

      <p>
      <li><strong>Instance-Aware Dynamic Neural Network Quantization</strong>
      <br>
      Zhenhua Liu, <strong>Yunhe Wang</strong>, Kai Han, Siwei Ma, Wen Gao
      <br>
      <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Instance-Aware_Dynamic_Neural_Network_Quantization_CVPR_2022_paper.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/Efficient-Computing">Pytorch code</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/DynamicQuant">MindSpore code</a>
      </p>

      <p>
      <li><strong>Source-Free Domain Adaptation via Distribution Estimation</strong>
      <br>
      Ning Ding, Yixing Xu, Yehui Tang, Chao Xu, <strong>Yunhe Wang</strong>, Dacheng Tao
      <br>
      <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Source-Free_Domain_Adaptation_via_Distribution_Estimation_CVPR_2022_paper.pdf">paper</a> 
      </p>

      <p>
      <li><strong>Multimodal Token Fusion for Vision Transformers</strong>
      <br>
      Yikai Wang, Xinghao Chen, Lele Cao, Wenbing Huang, Fuchun Sun, <strong>Yunhe Wang</strong>
      <br>
      <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multimodal_Token_Fusion_for_Vision_Transformers_CVPR_2022_paper.pdf">paper</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/TokenFusion">MindSpore code</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/noah-research">Pytorch code</a>
      </p>

      <p>
      <li><strong>Brain-Inspired Multilayer Perceptron With Spiking Neurons</strong>
      <br>
      Wenshuo Li, Hanting Chen, Jianyuan Guo, Ziyang Zhang, <strong>Yunhe Wang</strong>
      <br>
      <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Brain-Inspired_Multilayer_Perceptron_With_Spiking_Neurons_CVPR_2022_paper.pdf">paper</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/snn_mlp">MindSpore code</a>
      </p>

      <p>
      <li><strong>Hire-MLP: Vision MLP via Hierarchical Rearrangement</strong>
      <br>
      Jianyuan Guo, Yehui Tang, Kai Han, Xinghao Chen, Han Wu, Chao Xu, Chang Xu, <strong>Yunhe Wang</strong>
      <br>
      <em>CVPR</em> 2022 | <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Hire-MLP_Vision_MLP_via_Hierarchical_Rearrangement_CVPR_2022_paper.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/ggjy/Hire-Wave-MLP.pytorch">code</a>
      </p>

      <p>
      <li><strong>Transformer in Transformer</strong>
      <br>
      Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, <strong>Yunhe Wang</strong>
      <br>
      <em>NeurIPS</em> 2021 | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper/2021/file/854d9fca60b4bd07f9bb215d59ef5561-Paper.pdf">paper</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/CV-Backbones">code</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/TNT">MindSpore code</a> 
      </p>

      <p>
      <li><strong>Learning Frequency Domain Approximation for Binary Neural Networks</strong>
      <br>
      Yixing Xu, Kai Han, Chang Xu, Yehui Tang, Chunjing Xu, <strong>Yunhe Wang</strong>
      <br>
      <em>NeurIPS</em> 2021 | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper/2021/file/d645920e395fedad7bbbed0eca3fe2e0-Paper.pdf">paper</a> | <span style="color:red"> Oral Presentation</span>
      </p>

      <p>
      <li><strong>Dynamic Resolution Network</strong>
      <br>
      Mingjian Zhu*, Kai Han*, Enhua Wu, Qiulin Zhang, Ying Nie, Zhenzhong Lan, <strong>Yunhe Wang</strong>
      <br>
      <em>NeurIPS</em> 2021 (* equal contribution) | <a style="color: #447ec9" href="https://proceedings.neurips.cc/paper/2021/file/e56954b4f6347e897f954495eab16a88-Paper.pdf">paper</a> 
      </p>

      <p>
      <li><strong>DCT Inspired Feature Transform for Image Retrieval and Reconstruction</strong>
      <br>
      <strong>Yunhe Wang</strong>, Miaojing Shi, Shan You, Chao Xu
      <br>
      <em>IEEE TIP</em> 2016 | <a style="color: #447ec9" href="data/2016 TIP DCT feature.pdf">paper</a>
      </p>

      </ol>

    </p>
  </div>

<!-- The Services Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Services</h2>
      <p><li> Area Chair of <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</p>
      <p><li> Senior Program Committee Members of <a href="https://ijcai-21.org/">IJCAI 2021</a>, <a href="https://www.ijcai20.org/">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.</p>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a>, <a href="https://www.springer.com/journal/11263">IJCV</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE T-IP</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE T-KDE</a>, etc.</p>
      <p><li> Program Committee Members of ICCV 2021, AAAI 2021, ICLR 2021, NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.</p>
  </div>

  <!-- The Seleceted Honors & Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
    <p><li> 2020, <a href="https://mp.weixin.qq.com/s/dORL01lgFNDHgjp3KMJmiQ">Nomination for Outstanding Youth Paper Award</a>, <a href="https://worldaic.com.cn/portal/en/aboutus.html">WAIC</a></p>               
    <p><li> 2017, <a href="https://research.google/outreach/phd-fellowship/recipients/?category=2017">Google PhD Fellowship</a></p>
    <p><li> 2017, <a href="http://scholarship.baidu.com/">Baidu Scholarship</a></p>
    <p><li> 2017, President's PhD Scholarship, Peking University</p>
    <p><li> 2017, National Scholarship for Graduate Students</p>
    <p><li> 2016, National Scholarship for Graduate Students</p>
  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">

    Welcome to use this website's <a href="https://github.com/YunheWang/HomePage">source code</a>, just add a link back to here. <a href="https://www.wangyunhe.site/">&#10025;</a></br>

  <!-- Default Statcounter code for Wei Tang's Homepage
  https://tthinking.github.io -->
  No.
  <script type="text/javascript">
  var sc_project=12347113; 
  var sc_invisible=0; 
  var sc_security="21aca5d1"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script> Visitor Since Feb 2022. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a>
  <noscript>
    <div class="statcounter"><a title="Web Analytics Made Easy -
  StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12347113/0/21aca5d1/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
